# Отчет о сравнении производительности REST и gRPC сервисов глоссария

## 1. Описание тестируемых приложений

### 1.1 Процесс развертывания и работы сервиса

#### REST FastAPI сервис

**Расположение**: `mindmap-vkr-main/backend/`

**Шаги развертывания**:
1. Перейти в корень репозитория: `cd /home/krllkrnv/locusttest`
2. Запустить сервис: `./scripts/start_rest.sh`
3. Проверить доступность: `curl http://127.0.0.1:8000/api/health`

**Порт**: 8000

#### gRPC сервис

**Расположение**: `grpc-test-vkr-main/vkr-glossary-grpc-project/glossary-grpc/glossary-service/`

**Шаги развертывания**:
1. Перейти в корень репозитория: `cd /home/krllkrnv/locusttest`
2. Запустить сервис: `./scripts/start_grpc.sh`
3. Сервер запускается на порту 50052

### 1.2 Архитектура

Оба сервиса реализуют один и тот же «глоссарий терминов» и используют JSON‑файл как хранилище.  
Разница в интерфейсе: REST (FastAPI) vs gRPC (protobuf).

### 1.3 Используемые технологии

FastAPI, Uvicorn, Pydantic, grpcio, protobuf. Хранилище: JSON‑файл (не БД).

### 1.4 Использовалась ли БД

**Нет, полноценная база данных не используется.**

В качестве хранилища данных используется JSON файл (`data/terms.json`).

### 1.5 Какие данные возвращаются

REST возвращает JSON, gRPC — protobuf-сообщения.  
Основные операции: проверка здоровья сервиса, список терминов, получение термина по id, поиск, создание.

### 1.6 Какие данные необходимы для выполнения запроса на добавление

#### REST: POST /api/terms

Тело запроса: `term`, `definition` (обязательные), `category`, `related_terms` (опциональные).

#### gRPC: CreateTerm

Поля запроса аналогичны REST: `term`, `definition` (обязательные), `category`, `related_terms` (опциональные).

## 2. Настройки тестовой среды

### 2.1 Аппаратные ресурсы

**CPU**: 12th Gen Intel(R) Core(TM) i5-1240P  
- 12 физических ядер (Core(s) per socket: 12)  
- 16 логических CPU (CPU(s): 16)  
- Max frequency: 4.4 GHz

**RAM**: 16 GiB (Mem total: 15 GiB)

**Сеть**: localhost (оба сервиса и Locust на одной машине)

### 2.2 Архитектура стенда

**REST сервис**: 
- Запущен на `127.0.0.1:8000`
- Процесс: `uvicorn app.main:app`

**gRPC сервис**:
- Запущен на `127.0.0.1:50052`
- Процесс: `python glossary.py`

**Locust**:
- Запущен на той же машине
- Веб-интерфейс: `http://localhost:8089` (при интерактивном режиме)

### 2.3 Версия Locust

**Версия**: `locust 2.42.6 (Python 3.12.3)`

### 2.4 ОС/ПО (контекст)

- **OS/Kernel**: Linux 6.14.0-36-generic (Ubuntu 24.04.1)
- **Python**: 3.12.3
- **grpcio**: 1.76.0
- **protobuf**: 6.33.2

### 2.5 Дополнительные инструменты мониторинга

Дополнительные инструменты мониторинга не использовались (фиксировались метрики Locust).

## 3. Тестовые сценарии

### 3.1 Сценарий 1: Легкая нагрузка (Sanity Check)

**Цель**: Убедиться, что всё работает

**Логика поведения пользователя (task flow)**: один профиль нагрузки для всех сценариев (меняется только число пользователей / скорость набора / длительность).  
Веса задач: проверка здоровья 50%, чтение 45% (список/получение/поиск), создание 5% (CreateTerm). Паузы: 0.2–1.2 сек.

**Процесс подбора параметров**:
Использованы минимальные значения для быстрой проверки работоспособности стенда (sanity check).

**Конфигурация нагрузки** (финальные значения):
- Количество пользователей: 5
- Скорость набора пользователей: 1 пользователь/сек
- Длительность: 2 минуты

**Ожидания перед запуском (гипотезы)**:
- 0 ошибок
- Стабильная латентность
- Система работает корректно

**Фрагмент кода Locust**:
```python
@task(10)  # 50%
def health_check(self):
    self.client.get("/api/health", name="GET /api/health")
```

### 3.2 Сценарий 2: Рабочая нагрузка (Normal Load)

**Цель**: Подобрать параметры, имитирующие реалистичное использование

**Процесс подбора параметров**:
Итерации: 10 → 25 → 50 пользователей, затем финальный прогон.  
Выбрано: 50 пользователей (0 ошибок, RPS держится ровно, p95/p99 без резких скачков).

**Конфигурация нагрузки** (финальные значения):
- Количество пользователей: 50 (0 ошибок, стабильные метрики)
- Скорость набора пользователей: 5/сек (разгон до 50 за ~10 секунд)
- Длительность: 5 минут (достаточно для устойчивых метрик)

**Ожидания перед запуском (гипотезы)**:
- Стабильные метрики без деградации
- Минимальные ошибки (< 1%)
- Приемлемая латентность
- Стабильный RPS

### 3.3 Сценарий 3: Стресс-тест (Stress Test)

**Цель**: Выявить пределы производительности, найти момент наступления деградации

**Процесс подбора параметров и поиска точки деградации**:
Нагрузка увеличена относительно рабочего режима: до 100 пользователей (скорость набора ~10/сек), длительность 3 минуты.  
Деградацию фиксировал по росту p95/p99 и среднего времени ответа.

**Конфигурация нагрузки** (финальные значения для фиксации пределов):
- Количество пользователей: 100
- Скорость набора пользователей: 10/сек
- Длительность: 3 минуты

**Ожидания перед запуском (гипотезы)**:
- Выявить точку деградации
- Рост латентности при увеличении нагрузки
- Появление ошибок при превышении пределов
- Определить максимальный RPS до деградации

### 3.4 Сценарий 4: Тест на стабильность (Stability Test)

**Цель**: Проверить деградацию при длительной нагрузке

**Процесс подбора параметров**:
Использованы параметры рабочей нагрузки (50 пользователей, spawn 5/сек), длительность увеличена до 15 минут для проверки деградации метрик во времени.

**Конфигурация нагрузки** (финальные значения):
- Количество пользователей: 50
- Скорость набора пользователей: 5/сек
- Длительность: 15 минут

**Ожидания перед запуском (гипотезы)**:
- Отследить утечки памяти
- Проверить стабильность производительности во времени
- Выявить возможную деградацию со временем
- Зафиксировать изменение метрик в течение теста

## 4. Результаты тестирования

### 4.1 Основные метрики

#### Сценарий 1: Легкая нагрузка

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 6.86 |
| Среднее время ответа | 4.25 ms |
| p95 | 6 ms |
| p99 | 7 ms |
| Количество ошибок | 0 |
| Total Requests | 817 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 7.18 |
| Среднее время ответа | 2.25 ms |
| p95 | 3 ms |
| p99 | 5 ms |
| Количество ошибок | 0 |
| Total Requests | 856 |

**Графики/отчеты Locust**: `loadtest/out/rest_sanity.html`, `loadtest/out/grpc_sanity.html`

#### Сценарий 2: Рабочая нагрузка

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.45 |
| Среднее время ответа | 12.69 ms |
| p95 | 41 ms |
| p99 | 62 ms |
| Количество ошибок | 0 |
| Total Requests | 20,744 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.72 |
| Среднее время ответа | 3.53 ms |
| p95 | 5 ms |
| p99 | 35 ms |
| Количество ошибок | 0 |
| Total Requests | 20,850 |

**Графики/отчеты Locust**: `loadtest/out/rest_normal.html`, `loadtest/out/grpc_normal.html`

#### Сценарий 3: Стресс-тест

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 104.78 |
| Среднее время ответа | 236.43 ms |
| p95 | 520 ms |
| p99 | 730 ms |
| Количество ошибок | 0 |
| Total Requests | 18,726 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 128.88 |
| Среднее время ответа | 5.65 ms |
| p95 | 43 ms |
| p99 | 76 ms |
| Количество ошибок | 0 |
| Total Requests | 23,074 |

**Графики/отчеты Locust**: `loadtest/out/rest_stress.html`, `loadtest/out/grpc_stress.html`

#### Сценарий 4: Тест на стабильность

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 61.32 |
| Среднее время ответа | 113.22 ms |
| p95 | 330 ms |
| p99 | 480 ms |
| Количество ошибок | 0 |
| Total Requests | 55,149 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.27 |
| Среднее время ответа | 6.34 ms |
| p95 | 43 ms |
| p99 | 80 ms |
| Количество ошибок | 0 |
| Total Requests | 62,305 |

**Графики/отчеты Locust**: `loadtest/out/rest_stability.html`, `loadtest/out/grpc_stability.html`

### 4.2 Анализ результатов

#### 4.2.1 На каком количестве пользователей начинается деградация?

**REST API**:
- Normal (50): стабильно (p95 41 ms, p99 62 ms).
- Stress (100): сильный рост хвостов (p95 520 ms, p99 730 ms), ошибок нет.
- По history рост p95 заметен уже примерно с 60–70 пользователей.

**gRPC API**:
- Normal (50): стабильно (p95 5 ms).
- Stress (100): хвосты выросли, но без “обвала” (p95 43 ms, p99 76 ms), ошибок нет.

#### 4.2.2 Как изменяется латентность при росте нагрузки?

Итог:
- REST: на стресс‑нагрузке и на длительном прогоне время ответа сильно растёт (особенно p95/p99).
- gRPC: рост есть, но заметно меньше.

#### 4.2.3 Где «бутылочное горлышко»?

С высокой вероятностью упираемся в работу с JSON‑файлом при параллельных запросах (в REST хвосты растут сильнее). Сеть не влияет (localhost). Мониторинг CPU/Disk не делал.

#### 4.2.4 Отличаются ли результаты REST и gRPC?

Да:
- В sanity/normal gRPC быстрее по времени ответа при сопоставимом RPS.
- В stress gRPC удерживает большую пропускную способность (128.9 RPS vs 104.8 RPS) и значительно меньшую латентность.
- В stability REST демонстрирует деградацию (p95 330 ms), тогда как gRPC — заметно стабильнее (p95 43 ms).

## 5. Сравнение REST и gRPC

### 5.1 Численное сравнение латентности

| Сценарий | Протокол | Avg (ms) | p95 (ms) | p99 (ms) |
|----------|----------|----------|----------|----------|
| Sanity | REST | 4.25 | 6 | 7 |
| Sanity | gRPC | 2.25 | 3 | 5 |
| Normal | REST | 12.69 | 41 | 62 |
| Normal | gRPC | 3.53 | 5 | 35 |
| Stress | REST | 236.43 | 520 | 730 |
| Stress | gRPC | 5.65 | 43 | 76 |
| Stability | REST | 113.22 | 330 | 480 |
| Stability | gRPC | 6.34 | 43 | 80 |

### 5.2 Сравнение RPS

| Сценарий | REST RPS | gRPC RPS | Разница |
|----------|----------|----------|---------|
| Sanity | 6.86 | 7.18 | +4.7% |
| Normal | 69.45 | 69.72 | +0.4% |
| Stress | 104.78 | 128.88 | +23.0% |
| Stability | 61.32 | 69.27 | +13.0% |

### 5.3 Обнаружение различий в пропускной способности и задержках

По цифрам:
- **Рабочий режим (normal)**: при одинаковом RPS (~69.5) gRPC быстрее по среднему времени ответа (3.53 ms vs 12.69 ms, ≈3.6×).
- **Stress**: gRPC даёт +23% RPS и существенно меньшие p95/p99.

Различия наиболее заметны:
- на коротких запросах (healthcheck) и при высокой параллельности (stress/stability), где у REST сильнее проявляются накладные расходы и конкуренция за I/O.

### 5.4 Оценка влияния размера сообщений

**Размеры сообщений**:

| Операция | REST (JSON) | gRPC (protobuf) | Экономия |
|----------|-------------|-----------------|----------|
| Проверка здоровья | ~72 bytes | ~50 bytes | ~30.6% |
| Список терминов (normal) | ~4520 bytes | ~2855 bytes | ~36.8% |
| Создание термина (ответ) | ~168 bytes | ~105 bytes | ~37.5% |

Примечание: значения взяты из `Average Content Size` в отчетах Locust (размер тела ответа).

### 5.5 Оценка влияния сериализации

gRPC показывает меньшую латентность, что связано с использованием protobuf (бинарная сериализация) вместо JSON (текстовая).

### 5.6 Влияние сети

Тут всё на localhost, поэтому сеть почти не влияет. Разница в основном из‑за формата данных: JSON больше, protobuf компактнее.

### 5.7 Выводы о применимости каждого подхода

**Когда использовать REST**:
- когда важна простота интеграции и отладки;
- при невысоких нагрузках.

**Когда использовать gRPC**:
- при высоких нагрузках и низких задержках;
- для внутренних сервисов, где нужна скорость.

## 6. Заключение

### 6.1 Основные выводы

1. gRPC выигрывает по задержкам: в normal avg 3.53 ms vs 12.69 ms у REST (≈3.6× быстрее) при сопоставимом RPS.
2. На stress gRPC показывает большую пропускную способность (+23% RPS) и значительно меньшую латентность, тогда как REST деградирует по p95/p99 (сотни миллисекунд).
3. В stability REST демонстрирует деградацию (p95 330 ms), gRPC — заметно стабильнее (p95 43 ms).

### 6.2 Рекомендации по оптимизации

**Для REST сервиса**:
- заменить JSON-файл на базу данных (например, SQLite/PostgreSQL);
- при варианте с файлом: не писать в файл прямо во время ответа (очередь/отложенная запись), добавить кэш чтения и блокировку записи.

**Для gRPC сервиса**:
- аналогично: заменить JSON-файл на БД, оптимизировать запись;
- при необходимости увеличить пул потоков gRPC сервера и/или оптимизировать обработчики.

**Общее**: заменить JSON-файл на БД и/или оптимизировать запись (очередь/батчинг/блокировки), добавить кэш чтения.

### 6.3 Возможные улучшения эксперимента

- повторить прогоны 2–3 раза и сравнить распределения/средние значения;
- добавить мониторинг CPU/RAM/Disk I/O (`htop`, `iostat`) на stress/stability;
- провести тесты, когда клиент (Locust) и сервисы запущены на разных компьютерах/хостах, чтобы учесть влияние сети.

### 6.4 Ограничения проведённого тестирования

- тестирование на одной машине (localhost) — сетевые задержки почти отсутствуют;
- JSON-файл вместо БД — результаты чувствительны к I/O и не отражают поведение с реальной БД;
- отсутствие системного мониторинга — «бутылочное горлышко» определяется косвенно по метрикам Locust.

---

**Версия Locust**: 2.42.6


