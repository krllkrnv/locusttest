# Отчет о сравнении производительности REST и gRPC сервисов глоссария

## 1. Описание тестируемых приложений

### 1.1 Процесс развертывания и работы сервиса

#### REST FastAPI сервис

Сервис расположен в директории `mindmap-vkr-main/backend/`. Шаги развертывания:
1. Перейти в корень репозитория: `cd /home/krllkrnv/locusttest`
2. Запустить сервис: `./scripts/start_rest.sh`
3. Проверить доступность: `curl http://127.0.0.1:8000/api/health`

Сервис доступен на порту 8000.

#### gRPC сервис

Сервис находится в `grpc-test-vkr-main/vkr-glossary-grpc-project/glossary-grpc/glossary-service/`. Шаги развертывания:
1. Перейти в корень репозитория: `cd /home/krllkrnv/locusttest`
2. Запустить сервис: `./scripts/start_grpc.sh`

Сервер запускается на порту 50052.

### 1.2 Архитектура

Оба сервиса реализуют один и тот же глоссарий терминов и используют JSON-файл как хранилище. Разница заключается в интерфейсе: REST использует FastAPI, а gRPC работает с protobuf.

### 1.3 Используемые технологии

В проекте используются FastAPI, Uvicorn, Pydantic для REST-сервиса, а также grpcio и protobuf для gRPC-сервиса. В качестве хранилища данных применяется JSON-файл, полноценная база данных не используется.

### 1.4 Использовалась ли БД

Полноценная база данных не используется. В качестве хранилища данных применяется JSON-файл `data/terms.json`.

### 1.5 Какие данные возвращаются

REST-сервис возвращает данные в формате JSON, gRPC-сервис использует protobuf-сообщения. Оба сервиса поддерживают основные операции: проверку здоровья сервиса, получение списка терминов, получение термина по идентификатору, поиск терминов и создание новых терминов.

### 1.6 Какие данные необходимы для выполнения запроса на добавление

Для REST-сервиса (POST /api/terms) в теле запроса необходимо указать обязательные поля `term` и `definition`, а также опциональные `category` и `related_terms`. Для gRPC-сервиса (CreateTerm) поля запроса аналогичны: обязательные `term` и `definition`, опциональные `category` и `related_terms`.

## 2. Настройки тестовой среды

### 2.1 Аппаратные ресурсы

Тестирование проводилось на машине с процессором 12th Gen Intel(R) Core(TM) i5-1240P, который имеет 12 физических ядер и 16 логических процессоров с максимальной частотой 4.4 GHz. Объем оперативной памяти составляет 16 GiB (доступно около 15 GiB). Все компоненты системы, включая сервисы и Locust, работали на одной машине через localhost, поэтому сетевые задержки были минимальными.

### 2.2 Архитектура стенда

REST-сервис запускался на адресе `127.0.0.1:8000` через процесс `uvicorn app.main:app`. gRPC-сервис работал на `127.0.0.1:50052` через процесс `python glossary.py`. Locust запускался на той же машине, при интерактивном режиме веб-интерфейс был доступен по адресу `http://localhost:8089`.

### 2.3 Версия Locust

Использовалась версия Locust 2.42.6 на Python 3.12.3.

### 2.4 ОС/ПО (контекст)

Тестирование проводилось на Linux 6.14.0-36-generic (Ubuntu 24.04.1) с Python 3.12.3. Использовались библиотеки grpcio версии 1.76.0 и protobuf версии 6.33.2.

### 2.5 Дополнительные инструменты мониторинга

Дополнительные инструменты мониторинга не использовались. Все метрики фиксировались средствами Locust.

## 3. Тестовые сценарии

### 3.1 Сценарий 1: Легкая нагрузка (Sanity Check)

Целью этого сценария было убедиться, что система работает корректно. Логика поведения пользователя одинакова для всех сценариев, меняются только параметры нагрузки: количество пользователей, скорость их набора и длительность теста. В тестах используются разные типы запросов с разными пропорциями между ними: проверка здоровья выполняется чаще всего, затем идут операции чтения (список терминов, получение по ID, поиск), и реже всего выполняется создание новых терминов. Между запросами делаются паузы от 0.2 до 1.2 секунды для имитации реального поведения пользователей.

Для подбора параметров использовались минимальные значения, достаточные для быстрой проверки работоспособности стенда.

**Конфигурация нагрузки**:
- Количество пользователей: 5
- Скорость набора пользователей: 1 пользователь/сек
- Длительность: 2 минуты

**Ожидания перед запуском**:
- 0 ошибок
- Стабильное время ответа
- Корректная работа всех компонентов

Фрагмент кода Locust:

```python
@task(10)
def health_check(self):
    self.client.get("/api/health", name="GET /api/health")
```

### 3.2 Сценарий 2: Рабочая нагрузка (Normal Load)

Целью было подобрать параметры, имитирующие реалистичное использование системы. Подбор параметров проводился итеративно: сначала тестировалось 10 пользователей, затем 25, потом 50. В итоге выбрано 50 пользователей, так как при этом количестве не было ошибок, RPS держался стабильно, а значения p95 и p99 не показывали резких скачков.

**Конфигурация нагрузки**:
- Количество пользователей: 50 (0 ошибок, стабильные метрики)
- Скорость набора пользователей: 5/сек (разгон до 50 за ~10 секунд)
- Длительность: 5 минут (достаточно для устойчивых метрик)

**Ожидания перед запуском**:
- Стабильные метрики без деградации
- Минимальные ошибки (< 1%)
- Приемлемое время ответа
- Стабильный RPS

### 3.3 Сценарий 3: Стресс-тест (Stress Test)

Целью было выявить пределы производительности системы и найти момент наступления деградации. Нагрузка была увеличена относительно рабочего режима: до 100 пользователей со скоростью набора около 10 пользователей в секунду, длительность теста составила 3 минуты. Деградация фиксировалась по росту значений p95 и p99, а также по увеличению среднего времени ответа.

**Конфигурация нагрузки**:
- Количество пользователей: 100
- Скорость набора пользователей: 10/сек
- Длительность: 3 минуты

**Ожидания перед запуском**:
- Выявить точку деградации
- Рост времени ответа при увеличении нагрузки
- Появление ошибок при превышении пределов
- Определить максимальный RPS до деградации

### 3.4 Сценарий 4: Тест на стабильность (Stability Test)

Целью было проверить деградацию системы при длительной нагрузке. Для подбора параметров использовались значения рабочей нагрузки (50 пользователей, скорость набора 5 в секунду), но длительность теста была увеличена до 15 минут для проверки изменения метрик во времени.

**Конфигурация нагрузки**:
- Количество пользователей: 50
- Скорость набора пользователей: 5/сек
- Длительность: 15 минут

**Ожидания перед запуском**:
- Отследить утечки памяти
- Проверить стабильность производительности во времени
- Выявить возможную деградацию со временем
- Зафиксировать изменение метрик в течение теста

## 4. Результаты тестирования

### 4.1 Основные метрики

#### Сценарий 1: Легкая нагрузка

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 6.86 |
| Среднее время ответа | 4.25 ms |
| p95 | 6 ms |
| p99 | 7 ms |
| Количество ошибок | 0 |
| Total Requests | 817 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 7.18 |
| Среднее время ответа | 2.25 ms |
| p95 | 3 ms |
| p99 | 5 ms |
| Количество ошибок | 0 |
| Total Requests | 856 |

Графики и отчеты Locust сохранены в файлах `loadtest/out/rest_sanity.html` и `loadtest/out/grpc_sanity.html`.

#### Сценарий 2: Рабочая нагрузка

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.45 |
| Среднее время ответа | 12.69 ms |
| p95 | 41 ms |
| p99 | 62 ms |
| Количество ошибок | 0 |
| Total Requests | 20,744 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.72 |
| Среднее время ответа | 3.53 ms |
| p95 | 5 ms |
| p99 | 35 ms |
| Количество ошибок | 0 |
| Total Requests | 20,850 |

Графики и отчеты Locust сохранены в файлах `loadtest/out/rest_normal.html` и `loadtest/out/grpc_normal.html`.

#### Сценарий 3: Стресс-тест

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 104.78 |
| Среднее время ответа | 236.43 ms |
| p95 | 520 ms |
| p99 | 730 ms |
| Количество ошибок | 0 |
| Total Requests | 18,726 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 128.88 |
| Среднее время ответа | 5.65 ms |
| p95 | 43 ms |
| p99 | 76 ms |
| Количество ошибок | 0 |
| Total Requests | 23,074 |

Графики и отчеты Locust сохранены в файлах `loadtest/out/rest_stress.html` и `loadtest/out/grpc_stress.html`.

#### Сценарий 4: Тест на стабильность

**REST API**:

| Метрика | Значение |
|---------|----------|
| RPS | 61.32 |
| Среднее время ответа | 113.22 ms |
| p95 | 330 ms |
| p99 | 480 ms |
| Количество ошибок | 0 |
| Total Requests | 55,149 |

**gRPC API**:

| Метрика | Значение |
|---------|----------|
| RPS | 69.27 |
| Среднее время ответа | 6.34 ms |
| p95 | 43 ms |
| p99 | 80 ms |
| Количество ошибок | 0 |
| Total Requests | 62,305 |

Графики и отчеты Locust сохранены в файлах `loadtest/out/rest_stability.html` и `loadtest/out/grpc_stability.html`.

### 4.2 Анализ результатов

#### 4.2.1 На каком количестве пользователей начинается деградация?

Для REST API при нормальной нагрузке (50 пользователей) система работала стабильно с p95 равным 41 миллисекунде и p99 равным 62 миллисекундам. При стресс-нагрузке (100 пользователей) наблюдался сильный рост времени ответа у медленных запросов: p95 вырос до 520 миллисекунд, p99 до 730 миллисекунд, при этом ошибок не было. По данным истории теста, рост p95 становится заметным уже примерно с 60–70 пользователей.

Для gRPC API при нормальной нагрузке (50 пользователей) система работала стабильно с p95 равным 5 миллисекундам. При стресс-нагрузке (100 пользователей) время ответа у медленных запросов выросло, но без критического обвала: p95 составил 43 миллисекунды, p99 — 76 миллисекунд, ошибок не было.

#### 4.2.2 Как изменяется латентность при росте нагрузки?

При увеличении нагрузки время ответа изменяется по-разному для REST и gRPC. REST-сервис на стресс-нагрузке и при длительном прогоне показывает сильный рост времени ответа, особенно заметный по значениям p95 и p99. gRPC-сервис также демонстрирует рост времени ответа при увеличении нагрузки, но этот рост заметно меньше, чем у REST.

#### 4.2.3 Где «бутылочное горлышко»?

С высокой вероятностью основным ограничением является работа с JSON-файлом при параллельных запросах. Это особенно заметно для REST-сервиса, где время ответа у медленных запросов растет сильнее. Сеть практически не влияет на результаты, так как все компоненты работают на localhost. Системный мониторинг CPU и диска не проводился, поэтому точное определение узкого места выполнено косвенно по метрикам Locust.

#### 4.2.4 Отличаются ли результаты REST и gRPC?

Результаты REST и gRPC заметно отличаются. В сценариях sanity и normal gRPC показывает меньшее время ответа при сопоставимом RPS. В стресс-тесте gRPC удерживает большую пропускную способность (128.9 RPS против 104.8 RPS у REST) и значительно меньшее время ответа. В тесте на стабильность REST демонстрирует деградацию с p95 равным 330 миллисекундам, тогда как gRPC остается заметно стабильнее с p95 равным 43 миллисекундам.

## 5. Сравнение REST и gRPC

### 5.1 Численное сравнение латентности

| Сценарий | Протокол | Avg (ms) | p95 (ms) | p99 (ms) |
|----------|----------|----------|----------|----------|
| Sanity | REST | 4.25 | 6 | 7 |
| Sanity | gRPC | 2.25 | 3 | 5 |
| Normal | REST | 12.69 | 41 | 62 |
| Normal | gRPC | 3.53 | 5 | 35 |
| Stress | REST | 236.43 | 520 | 730 |
| Stress | gRPC | 5.65 | 43 | 76 |
| Stability | REST | 113.22 | 330 | 480 |
| Stability | gRPC | 6.34 | 43 | 80 |

### 5.2 Сравнение RPS

| Сценарий | REST RPS | gRPC RPS | Разница |
|----------|----------|----------|---------|
| Sanity | 6.86 | 7.18 | +4.7% |
| Normal | 69.45 | 69.72 | +0.4% |
| Stress | 104.78 | 128.88 | +23.0% |
| Stability | 61.32 | 69.27 | +13.0% |

### 5.3 Обнаружение различий в пропускной способности и задержках

В рабочем режиме (normal) при практически одинаковом RPS около 69.5 запросов в секунду gRPC показывает меньшее среднее время ответа: 3.53 миллисекунд против 12.69 миллисекунд у REST, что примерно в 3.6 раза быстрее. В стресс-тесте gRPC дает на 23% больше RPS и существенно меньшие значения p95 и p99.

Различия наиболее заметны на коротких запросах, таких как проверка здоровья сервиса, и при высокой параллельности в стресс-тестах и тестах на стабильность, где у REST сильнее проявляются накладные расходы и конкуренция за операции ввода-вывода.

### 5.4 Оценка влияния размера сообщений

Размеры сообщений различаются между REST и gRPC:

| Операция | REST (JSON) | gRPC (protobuf) | Экономия |
|----------|-------------|-----------------|----------|
| Проверка здоровья | ~72 bytes | ~50 bytes | ~30.6% |
| Список терминов (normal) | ~4520 bytes | ~2855 bytes | ~36.8% |
| Создание термина (ответ) | ~168 bytes | ~105 bytes | ~37.5% |

Значения взяты из метрики Average Content Size в отчетах Locust, которая показывает размер тела ответа.

### 5.5 Оценка влияния сериализации

gRPC показывает меньшее время ответа, что связано с использованием protobuf для бинарной сериализации вместо текстового формата JSON, применяемого в REST.

### 5.6 Влияние сети

Поскольку все компоненты работали на localhost, сеть практически не влияла на результаты. Разница в производительности в основном связана с форматом данных: JSON занимает больше места, чем компактный protobuf.

### 5.7 Выводы о применимости каждого подхода

REST стоит использовать, когда важна простота интеграции и отладки, а также при невысоких нагрузках. gRPC лучше подходит для случаев, когда требуются высокие нагрузки и низкие задержки, а также для внутренних сервисов, где важна скорость работы.

## 6. Заключение

### 6.1 Основные выводы

gRPC выигрывает по времени ответа: в нормальном режиме среднее время ответа составляет 3.53 миллисекунд против 12.69 миллисекунд у REST, что примерно в 3.6 раза быстрее при сопоставимом RPS. На стресс-нагрузке gRPC показывает большую пропускную способность (на 23% больше RPS) и значительно меньшее время ответа, тогда как REST демонстрирует деградацию по значениям p95 и p99, которые достигают сотен миллисекунд. В тесте на стабильность REST показывает деградацию с p95 равным 330 миллисекундам, тогда как gRPC остается заметно стабильнее с p95 равным 43 миллисекундам.

### 6.2 Рекомендации по оптимизации

**Для REST сервиса**:
- Заменить JSON-файл на базу данных (например, SQLite/PostgreSQL)
- При варианте с файлом: не писать в файл прямо во время ответа (очередь/отложенная запись), добавить кэш чтения и блокировку записи

**Для gRPC сервиса**:
- Аналогично: заменить JSON-файл на БД, оптимизировать запись
- При необходимости увеличить пул потоков gRPC сервера и/или оптимизировать обработчики

**Общее**: заменить JSON-файл на БД и/или оптимизировать запись (очередь/батчинг/блокировки), добавить кэш чтения.

### 6.3 Возможные улучшения эксперимента

- Повторить прогоны 2–3 раза и сравнить распределения/средние значения
- Добавить мониторинг CPU/RAM/Disk I/O (`htop`, `iostat`) на stress/stability
- Провести тесты, когда клиент (Locust) и сервисы запущены на разных компьютерах/хостах, чтобы учесть влияние сети

### 6.4 Ограничения проведённого тестирования

- Тестирование на одной машине (localhost) — сетевые задержки почти отсутствуют
- JSON-файл вместо БД — результаты чувствительны к I/O и не отражают поведение с реальной БД
- Отсутствие системного мониторинга — «бутылочное горлышко» определяется косвенно по метрикам Locust

---

**Версия Locust**: 2.42.6
