# Отчет о сравнении производительности REST и gRPC сервисов глоссария

Этот репозиторий содержит два варианта одного и того же сервиса "глоссарий терминов" (REST и gRPC) и набор нагрузочных тестов на Locust.

**Структура репозитория**:
- `mindmap-vkr-main/backend/` — REST API (FastAPI)
- `grpc-test-vkr-main/vkr-glossary-grpc-project/glossary-grpc/glossary-service/` — gRPC сервер
- `loadtest/` — сценарии Locust (`locustfile_rest.py`, `locustfile_grpc.py`), скрипты запуска, HTML/CSV артефакты прогонов в `loadtest/out/`

## Тестируемые приложения

Оба сервиса реализуют один и тот же глоссарий терминов и используют JSON-файл `data/terms.json` как хранилище. Разница в интерфейсе: REST использует FastAPI, gRPC работает с protobuf.

**Запуск сервисов**:
```bash
# REST (порт 8000)
./scripts/start_rest.sh

# gRPC (порт 50052)
./scripts/start_grpc.sh

# Проверка
curl http://127.0.0.1:8000/api/health
```

**Технологии**: FastAPI/Uvicorn/Pydantic для REST, grpcio/protobuf для gRPC. Версии: Python 3.12.3, Locust 2.42.6, grpcio 1.76.0, protobuf 6.33.2.

## Тестовая среда

Тестирование на одной машине (Intel i5-1240P, 12 ядер, 16 логических процессоров, 16 GiB RAM, Ubuntu 24.04.1). Все компоненты работали через localhost, поэтому сетевые задержки минимальны — это ограничение эксперимента.

Сервисы запускались как обычные процессы (`uvicorn app.main:app` для REST, `python glossary.py` для gRPC), Locust — в headless режиме. Системный мониторинг (CPU/Disk I/O) не использовался, только метрики Locust.

## Тестовые сценарии

Логика поведения пользователя одинакова для всех сценариев (см. `loadtest/locustfile_rest.py` и `loadtest/locustfile_grpc.py`): проверка здоровья выполняется чаще всего (weight=10), затем операции чтения (список, получение по ID, поиск), реже всего — создание терминов. Паузы между запросами 0.2–1.2 секунды.

### Легкая нагрузка (Sanity Check)

Параметры: 5 пользователей, spawn rate 1/сек, длительность 2 минуты. Цель — быстрая проверка работоспособности.

**Результаты**:

REST API: RPS 6.86, среднее время ответа 4.25 ms, p95 6 ms, p99 7 ms, ошибок 0, всего запросов 817.

gRPC API: RPS 7.18, среднее время ответа 2.25 ms, p95 3 ms, p99 5 ms, ошибок 0, всего запросов 856.

Отчеты: `loadtest/out/rest_sanity.html`, `loadtest/out/grpc_sanity.html`

### Рабочая нагрузка (Normal Load)

Подбор параметров итеративный: сначала 10 пользователей, затем 25, потом 50. Остановились на 50 пользователях — при этом количестве ошибок не было, RPS стабилен, p95/p99 без резких скачков. Spawn rate 5/сек (разгон до 50 за ~10 секунд), длительность 5 минут.

**Результаты**:

REST API: RPS 69.45, среднее время ответа 12.69 ms, p95 41 ms, p99 62 ms, ошибок 0, всего запросов 20,744.

gRPC API: RPS 69.72, среднее время ответа 3.53 ms, p95 5 ms, p99 35 ms, ошибок 0, всего запросов 20,850.

Отчеты: `loadtest/out/rest_normal.html`, `loadtest/out/grpc_normal.html`

### Стресс-тест

100 пользователей, spawn rate 10/сек, длительность 3 минуты. Деградация фиксировалась по росту p95/p99 и среднего времени ответа.

**Результаты**:

REST API: RPS 104.78, среднее время ответа 236.43 ms, p95 520 ms, p99 730 ms, ошибок 0, всего запросов 18,726.

gRPC API: RPS 128.88, среднее время ответа 5.65 ms, p95 43 ms, p99 76 ms, ошибок 0, всего запросов 23,074.

Отчеты: `loadtest/out/rest_stress.html`, `loadtest/out/grpc_stress.html`

**Наблюдение**: У REST при 100 пользователях p95 вырос до 520 ms (против 41 ms при 50), у gRPC рост был меньше (43 ms против 5 ms). По графикам в отчетах Locust, у REST рост p95 становится заметным примерно с 60–70 пользователей.

### Тест на стабильность

50 пользователей (как в рабочей нагрузке), spawn rate 5/сек, длительность 15 минут. Проверка изменения метрик во времени.

**Результаты**:

REST API: RPS 61.32, среднее время ответа 113.22 ms, p95 330 ms, p99 480 ms, ошибок 0, всего запросов 55,149.

gRPC API: RPS 69.27, среднее время ответа 6.34 ms, p95 43 ms, p99 80 ms, ошибок 0, всего запросов 62,305.

Отчеты: `loadtest/out/rest_stability.html`, `loadtest/out/grpc_stability.html`

**Наблюдение**: У REST за 15 минут p95 вырос до 330 ms (против 41 ms в 5-минутном тесте), у gRPC остался на уровне 43 ms. Это указывает на деградацию REST при длительной нагрузке.

## Анализ результатов

### Деградация при росте нагрузки

REST: при 50 пользователях p95 41 ms, p99 62 ms. При 100 пользователях p95 520 ms, p99 730 ms. По графикам в `loadtest/out/rest_stress.html`, рост p95 заметен примерно с 60–70 пользователей.

gRPC: при 50 пользователях p95 5 ms. При 100 пользователях p95 43 ms, p99 76 ms — рост есть, но без критического обвала.

### Изменение латентности

REST показывает сильный рост времени ответа на стресс-нагрузке и при длительном прогоне (особенно p95/p99). gRPC также демонстрирует рост, но заметно меньше.

### Бутылочное горлышко

По совокупности метрик (рост p95/p99 без ошибок, синхронная работа с `data/terms.json` в обоих сервисах) наиболее вероятное ограничение — доступ к файловому хранилищу при параллельных запросах (конкуренция за I/O, синхронное чтение/запись).

**Важно**: это гипотеза на основании метрик Locust. Без мониторинга CPU/Disk I/O и профилирования обработчиков узкое место фиксируется только косвенно. Сеть на результаты почти не влияет (localhost), но это ограничение эксперимента — в реальности сетевые задержки могут изменить картину.

### Различия REST и gRPC

В sanity и normal gRPC показывает меньшее время ответа при сопоставимом RPS. В стресс-тесте gRPC удерживает большую пропускную способность (128.9 RPS против 104.8 RPS у REST) и значительно меньшее время ответа. В тесте на стабильность REST демонстрирует деградацию (p95 330 ms), gRPC остается стабильнее (p95 43 ms).

## Сравнение REST и gRPC

### Латентность

| Сценарий | Протокол | Avg (ms) | p95 (ms) | p99 (ms) |
|----------|----------|----------|----------|----------|
| Sanity | REST | 4.25 | 6 | 7 |
| Sanity | gRPC | 2.25 | 3 | 5 |
| Normal | REST | 12.69 | 41 | 62 |
| Normal | gRPC | 3.53 | 5 | 35 |
| Stress | REST | 236.43 | 520 | 730 |
| Stress | gRPC | 5.65 | 43 | 76 |
| Stability | REST | 113.22 | 330 | 480 |
| Stability | gRPC | 6.34 | 43 | 80 |

### RPS

| Сценарий | REST RPS | gRPC RPS | Разница |
|----------|----------|----------|---------|
| Sanity | 6.86 | 7.18 | +4.7% |
| Normal | 69.45 | 69.72 | +0.4% |
| Stress | 104.78 | 128.88 | +23.0% |
| Stability | 61.32 | 69.27 | +13.0% |

В рабочем режиме (normal) при практически одинаковом RPS (~69.5) gRPC показывает среднее время ответа 3.53 ms против 12.69 ms у REST (примерно в 3.6 раза быстрее). В стресс-тесте gRPC дает на 23% больше RPS и существенно меньшие p95/p99.

### Размер сообщений

По метрике Average Content Size в отчетах Locust:

| Операция | REST (JSON) | gRPC (protobuf) | Экономия |
|----------|-------------|-----------------|----------|
| Проверка здоровья | ~72 bytes | ~50 bytes | ~30.6% |
| Список терминов | ~4520 bytes | ~2855 bytes | ~36.8% |
| Создание термина (ответ) | ~168 bytes | ~105 bytes | ~37.5% |

gRPC показывает меньшее время ответа, что связано с использованием protobuf для бинарной сериализации вместо текстового JSON. Поскольку все компоненты работали на localhost, сеть почти не влияла — разница в основном от формата данных.

## Выводы

gRPC выигрывает по времени ответа: в нормальном режиме среднее время ответа 3.53 ms против 12.69 ms у REST (примерно в 3.6 раза быстрее при сопоставимом RPS). На стресс-нагрузке gRPC показывает большую пропускную способность (на 23% больше RPS) и значительно меньшее время ответа, тогда как REST демонстрирует деградацию (p95/p99 достигают сотен миллисекунд). В тесте на стабильность REST показывает деградацию (p95 330 ms), gRPC остается стабильнее (p95 43 ms).

**Рекомендации по оптимизации**:

Для REST: заменить JSON-файл на БД (SQLite/PostgreSQL). Если оставлять файл — не писать на критическом пути ответа (очередь/отложенная запись), добавить кэш чтения и корректную блокировку записи.

Для gRPC: аналогично — заменить JSON-файл на БД, оптимизировать запись. При необходимости увеличить пул потоков gRPC сервера.

**Общее**: убрать синхронные операции с `terms.json` с критического пути и/или перейти на БД; добавить базовый мониторинг для подтверждения причин деградации.

**Ограничения эксперимента**:
- Тестирование на одной машине (localhost) — сетевые задержки почти отсутствуют
- JSON-файл вместо БД — результаты чувствительны к I/O и не отражают поведение с реальной БД
- Отсутствие системного мониторинга — бутылочное горлышко определяется косвенно по метрикам Locust
- Один прогон каждого сценария — для статистической значимости нужны повторные прогоны

**Возможные улучшения**:
- Повторить прогоны 2–3 раза и сравнить распределения/средние значения
- Добавить мониторинг CPU/RAM/Disk I/O (`htop`, `iostat`) на stress/stability
- Провести тесты, когда клиент (Locust) и сервисы запущены на разных хостах, чтобы учесть влияние сети

---

**Версия Locust**: 2.42.6
